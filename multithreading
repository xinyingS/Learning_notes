Reference from: https://www.udemy.com/multithreading-and-parallel-computing-in-java/


一、Course Architechture
    1. Basic multithreading
       (1) Process vs thread
       (2) Threads, runnables
       (3) Volatile, join(), notify()
       (4) Low and high level concurrency
    2. Complex problems
       (1) Library project
       (2) Dining philosophers problem
       (3) Simulation: mine sweeper
       (4) Conway's game of life
    3. Parellel Algorithm

二、

  Threads: There are various stages -> thread is born, it is started, it runs and it dies.

  (1) new    -> When we instantiate a thread it is in this state until we start it
                ~ start()


  (2) runnable   -> After we have started the thread. The thread is executing its task in this state.


  (3) running


  (4) waiting     ->  When a thread is waiting: for example. for another thread to finish its task.
                      When other thread signals -> this thread goes back to the, runnable's state.
                      ~ wait() and sleep().


  (5) dead        ->  After the thread finishes its task.



   1.
     Sequential

     multithreading  ->
     concurrency    -> at same time

   2.
     Thread join() -> waits for thread died (to finish it's task)

   3. Volatile -> slower -> threads to visit same area(RAM: Main memory)
      Cache  -> faster -> only one thread (located in it) can visit

   4. DeadLock vs LiveLock
      DeadLock in block state; LiveLock not in block state, threads communicate each other
      but they are too busy responding to each other to resume work.

   5. Synchronized

      public synchronized static void method1(){}  -> equal to lock the whole class,
      public synchronized static void method2(){}  -> no chance to execute same time

      //synchronized block
      |   public static void method1(){
              synchronized(className.class){
                  ...;
              }
          }
      |
          public static void method2(){
              synchronized(className.class){
                  ...;
              }
          }
          这种方法还是锁住同一个class.

      improve method:
      private Object lock1 = new Object();
      private Object lock2 = new Object();
      public static void method1(){
              synchronized(lock1){
                  ...;
              }
      }

      public static void method2(){
          synchronized(lock2){
              ...;
          }
      }

    6. wait() vs notify()
       (1) must same lock (same class)
       (2) notify() random wake up already wait() threads
       (3) if all, we should use notifyAll()

       Simply put, it depends on why your threads are waiting to be notified. Do you want to tell one of the waiting threads that something happened, or do you want to tell all of them at the same time?

       In some cases, all waiting threads can take useful action once the wait finishes. An example would be a set of threads waiting for a certain task to finish; once the task has finished,

       all waiting threads can continue with their business. In such a case you would use notifyAll() to wake up all waiting threads at the same time.

       Another case, for example mutually exclusive locking, only one of the waiting threads can do something useful after being notified (in this case acquire the lock). In such a case, you would rather use notify(). Properly implemented,

       you could use notifyAll() in this situation as well, but you would unnecessarily wake threads that can't do anything anyway.


    7. Locks
       (1) ReentrantLock -> implement the Lock interface.

           - it has the same behavior as the "synchronized approach"
           - of course it has some additional features

             new ReentrantLock(boolean fairnessParameter)
                 - fairness parameter: if it is set to be true --> the longest waiting thread will get the lock

                   fairness == false --> there is no access order.

              IMPORTANT : we have to use try- catch block when doing critical section
                              that may throw exceptions
                              ~ we call unlock() in the finally block.
                              (if we not unlock(), may be cause deadLock)

      (2) some resources need to be consistent.
          so synchronized or lock(), unlock() -> same function

          The advantage of lock() and unlock() -> we can put lock() and unlock() code anywhere we want.

    8. condition.await() && condition.signal() -> 用于ReentrantLock
     ->  wait()              notify()

       use:
       Lock lock = new ReentrantLock();
       Condition condition = lock.newCondition();

    9. Semaphores:
       Semaphores are variables or abstract data type that are used for controlling access to a common resource.
       It's a record of how many units of a particular resource are available... wait until a unit of the resource becomes available.

       (1)Counting Semaphore: allows an arbitrary resource count.
       (2)Binary Semaphore: Semaphores which are restricted to the values 0 and 1.

       eg:
       facebook server there are 10000 user want to download the same picture at the same time, so we must control the thread number.

  10。 Executors
       1.) ExecutorService es = Executors.newCachedThreadPool();
	    	- going to return an executorService that can dynamically
	    		reuse threads
	  		- before starting a job -> it going to check whether there are any threads that
	  			finished the job...reuse them
	  		- if there are no waiting threads -> it is going to create another one
	  		- good for the processor ... effective solution !!!

	  	2.) ExecutorService es = Executors.newFixedThreadPool(N);
	  		- maximize the number of threads
	  		- if we want to start a job -> if all the threads are busy, we have to wait for one
	  			to terminate

	  	3.) ExecutorService es = Executors.newSingleThreadExecutor();
	  		It uses a single thread for the job

	  		execute() -> runnable + callable
	  		submit() -> runnable

        .shutdown() -> initiates an orderly shutdown in which previously submitted tasks are executed, but no new
                       tasks will be accepted.

  11. Callable vs Runnable

      The Callable interface is similar to Runnable, in that both are designed for classes whose instances are potentially executed by another thread.
      A Runnable, however, does not return a result and cannot throw a checked exception.

      detail: Reference -> https://www.geeksforgeeks.org/callable-future-java/
      (1) The need for callable
          There are two ways of creating threads – one by extending the Thread class and other by creating a thread with a Runnable.
          However, one feature lacking in  Runnable is that we cannot make a thread return result when it terminates, i.e. when run() completes.
          For supporting this feature, the Callable interface is present in Java.
      (2) Callable vs Runnable
          For implementing Runnable, the run() method needs to be implemented which does not return anything,
          while for a Callable, the call() method needs to be implemented which returns a result on completion.
          Note that a thread can’t be created with a Callable, it can only be created with a Runnable.
          Another difference is that the call() method can throw an exception whereas run() cannot.
      (3)Future:
          When the call() method completes, answer must be stored in an object known to the main thread, so that the main thread can know about the result that the thread returned.
          How will the program store and obtain this result later? For this, a Future object can be used. Think of a Future as an object that holds the result – it may not hold it right now,
          but it will do so in the future (once the Callable returns).
          Thus, a Future is basically one way the main thread can keep track of the progress and result from other threads. To implement this interface, 5 methods have to be overridden,
          but as the example below uses a concrete implementation from the library, only the important methods are listed here.

  *12. Latch -> CountDownLatch -> (multiple threads can wait for each other)
       This is used to synchronize one or more tasks by forcing them to wait for the completion of a set of operations being performed by other tasks

    		- You give an initial count to a CountDownLatch object, and any task that calls await()
   				on that object will block until the count reaches zero

    		- Other tasks may call countDown() on the object to reduce the count, presumably when a task finishes its job
    		- A CountDownLatch is designed to be used in a one-shot fashion; the count cannot be reset !!!
    				If you need a version that resets the count, you can use a CyclicBarrier instead

   		  - The tasks that call countDown() are not blocked when they make that call. Only the call to await() is blocked until the count reaches zero

     		A typical use is to divide a problem into n independently solvable tasks and create a CountDownLatch with a value of n.
    		When each task is finished it calls countDown() on the latch. Tasks waiting for the problem to be solved call await()
    		on the latch to hold themselves back until it is completed

        For e.g.:
        you want to trigger something after 10000 users download an image.

        await() -> wait all the threads finish their tasks.

 *13. CyclicBarrier
       A CyclicBarrier is used in situations where you want to create a group of
       tasks to perform work in parallel + wait until they are all finished before
       moving on to the next step
       -> something like join()
       -> something like CountDownLatch

       CountDownLatch: one-shot event CyclicBarrier: it can be reused over and over
       again.

            + cyclicBarrier has a barrier action: a runnable, that will run automatically
              when the count reaches 0 !!

       new CyclicBarrier(N) -> N threads will wait for each other

       WE CAN NOT REUSE LATCHES BUT WE CAN REUSE CyclicBarriers --> reset() !!!

  14. BlockingQueues

      BlockingQueue -> an interface that represents a queue that is thread safe
  		      Put items or take items from it ...

 		  For example: one thread putting items into the queue and another thread taking items from it
 			at the same time !!!
 				 We can do it with producer-consumer pattern !!!

 		     put() putting items to the queue
 		     take() taking items from the queue

  15. DelayQueue  ->(server/ framework application)

    This is an unbounded BlockingQueue of objects that implement the Delayed
    interface

    - DelayQueue keeps the elements internally until a certain delay has expired

    - an object can only be taken from the queue when its delay has expired !!! -

    We cannot place null items in the queue - The queue is sorted so that the
    object at the head has a delay that has expired for the longest time.

    If no delay has expired, then there is no head element and poll( ) will
    return null

    size() return the count of both expired and unexpired items !!!

  16. PriorityQueue

      It implements the BlockingQueue interface

 	    - unbounded concurrent queue
 	    - it uses the same ordering rules as the java.util.PriorityQueue class -> have to implement the COmparable interface
 			      The comparable interface will determine what will the order in the queue

 			      The priority can be the same compare() == 0 case

      - no null items !!!

   17. ConcurrentHashMap

       A Map providing thread safety and atomicity guarantees.
       Memory consistency effects: As with other concurrent collections, actions in a thread prior to placing an object into a ConcurrentMap as a key or value happen-before actions subsequent to the access or removal of that object from the ConcurrentMap in another thread.

       This interface is a member of the Java Collections Framework.

       note:
       If you really want to synchronized in nonsynchronized data structure.
       use Collections.synchronizedList(...); -> slow

   18. Exchanger

        With the help of Exchanger -> two threads can exchange objects

        exchange() -> exchanging objects is done via one of the two exchange()
        methods

 	      For example: genetic algorithms, training neural networks

三、进程同步

   1. 临界区
   对临界资源进行访问的那段代码称为临界区。

   为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。
   // entry section
   // critical section;
   // exit section

   2. 同步与互斥
   同步：多个进程按一定顺序执行；
   互斥：多个进程在同一时刻只有一个进程能进入临界区。

   3. 信号量
   它是一个计数器，用于为多个进程提供对共享数据对象的访问。
   信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

   down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
   up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。
   down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

   如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。

四、进程通信

    进程同步与进程通信很容易混淆，它们的区别在于：

      进程同步：控制多个进程按一定顺序执行；
      进程通信：进程间传输信息。
    进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

    1、 管道
    2、 FIFO
    3、消息队列
    4、共享存储
    5、套件字
